{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**IMPORT DATA AND LIBRARIES**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Reading CSV from link\n",
    "def read_csv_from_link(url):\n",
    "    path = 'https://drive.google.com/uc?export=download&id='+url.split('/')[-2]\n",
    "    df = pd.read_csv(path,delimiter=\"\\t\",error_bad_lines=False, header=None)\n",
    "    return df\n",
    "\n",
    "# Loading All Data\n",
    "tamil_train = read_csv_from_link('https://drive.google.com/file/d/15auwrFAlq52JJ61u7eSfnhT9rZtI5sjk/view?usp=sharing')\n",
    "tamil_dev = read_csv_from_link('https://drive.google.com/file/d/1Jme-Oftjm7OgfMNLKQs1mO_cnsQmznRI/view?usp=sharing')\n",
    "# mal_train = read_csv_from_link('https://drive.google.com/file/d/13JCCr-IjZK7uhbLXeufptr_AxvsKinVl/view?usp=sharing')\n",
    "# mal_dev = read_csv_from_link('https://drive.google.com/file/d/1J0msLpLoM6gmXkjC6DFeQ8CG_rrLvjnM/view?usp=sharing')\n",
    "# kannada_train = read_csv_from_link('https://drive.google.com/file/d/1XuOhSpdK8qsbO-lZHrIcVaU5FsCXc05T/view?usp=sharing')\n",
    "# kannada_dev = read_csv_from_link('https://drive.google.com/file/d/164zYZOeXIwt5jl3NggJU0CWRyD2fRT9z/view?usp=sharing')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Not_offensive                           25425\n",
      "Offensive_Untargetede                    2906\n",
      "Offensive_Targeted_Insult_Group          2557\n",
      "Offensive_Targeted_Insult_Individual     2343\n",
      "not-Tamil                                1454\n",
      "Offensive_Targeted_Insult_Other           454\n",
      "Name: label, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Tamil Preprocess\n",
    "tamil_train = tamil_train.iloc[:, 0:2]\n",
    "tamil_train = tamil_train.rename(columns={0: \"text\", 1: \"label\"})\n",
    "tamil_dev = tamil_dev.iloc[:, 0:2]\n",
    "tamil_dev = tamil_dev.rename(columns={0: \"text\", 1: \"label\"})\n",
    "\n",
    "# Stats\n",
    "tamil_train['label'] = pd.Categorical(tamil_train.label)\n",
    "tamil_dev['label'] = pd.Categorical(tamil_dev.label)\n",
    "print(tamil_train['label'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**PREPROCESS_DATA**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "import re\n",
    "\n",
    "def remove_emoji(string):\n",
    "    emoji_pattern = re.compile(\"[\"\n",
    "                               u\"\\U0001F600-\\U0001F64F\"  # emoticons\n",
    "                               u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n",
    "                               u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n",
    "                               u\"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n",
    "                               u\"\\U00002500-\\U00002BEF\"  # chinese char\n",
    "                               u\"\\U00002702-\\U000027B0\"\n",
    "                               u\"\\U00002702-\\U000027B0\"\n",
    "                               u\"\\U000024C2-\\U0001F251\"\n",
    "                               u\"\\U0001f926-\\U0001f937\"\n",
    "                               u\"\\U00010000-\\U0010ffff\"\n",
    "                               u\"\\u2640-\\u2642\"\n",
    "                               u\"\\u2600-\\u2B55\"\n",
    "                               u\"\\u200d\"\n",
    "                               u\"\\u23cf\"\n",
    "                               u\"\\u23e9\"\n",
    "                               u\"\\u231a\"\n",
    "                               u\"\\ufe0f\"  # dingbats\n",
    "                               u\"\\u3030\"\n",
    "                               \"]+\", flags=re.UNICODE)\n",
    "    return emoji_pattern.sub(r'', string)\n",
    "\n",
    "def hasNumbers(inputString):\n",
    "  return any(char.isdigit() for char in inputString)\n",
    "\n",
    "def process(text):\n",
    "  text = text.lower()\n",
    "  text = remove_emoji(text)\n",
    "  table = str.maketrans('', '', string.punctuation)\n",
    "  stripped = text.translate(table)\n",
    "  words = stripped.split(\" \")\n",
    "  now_text = \"\"\n",
    "  for word in words:\n",
    "    if(not hasNumbers(word)):\n",
    "      now_text += word+\" \" \n",
    "  return now_text\n",
    "\n",
    "train_text = []\n",
    "for key, value in tamil_train['text'].iteritems(): \n",
    "  train_text.append(process(value))\n",
    "\n",
    "dev_text = []\n",
    "for key, value in tamil_dev['text'].iteritems(): \n",
    "  dev_text.append(process(value))\n",
    "tamil_train['text'] = pd.DataFrame(train_text)\n",
    "tamil_dev['text'] = pd.DataFrame(dev_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**LOADING SENTENCE EMBEDDINGS**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_dense_train = np.load('../sentence_embeddings/cnn_skipgram_emb_train.npy')\n",
    "x_dense_test = np.load('../sentence_embeddings/cnn_skipgram_emb_test.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = np.array(tamil_train[\"label\"])\n",
    "y_test = np.array(tamil_dev[\"label\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "coded = dict({'Not_offensive':0, 'Offensive_Targeted_Insult_Group':1,\n",
    "       'Offensive_Targeted_Insult_Individual':2,\n",
    "       'Offensive_Targeted_Insult_Other':3, 'Offensive_Untargetede':4,\n",
    "       'not-Tamil' :5})\n",
    "\n",
    "for i,j in enumerate(y_train):\n",
    "    y_train[i] = coded[j]\n",
    "for i,j in enumerate(y_test):\n",
    "    y_test[i] = coded[j]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TESTING THE EMBEDDINGS ON ML MODELS AS BASELINES**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**XGBOOST**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\teval-merror:0.27484\ttrain-merror:0.12428\n",
      "[1]\teval-merror:0.27279\ttrain-merror:0.10831\n",
      "[2]\teval-merror:0.26914\ttrain-merror:0.10288\n",
      "[3]\teval-merror:0.26892\ttrain-merror:0.09585\n",
      "[4]\teval-merror:0.27119\ttrain-merror:0.09189\n",
      "[5]\teval-merror:0.26869\ttrain-merror:0.08811\n",
      "[6]\teval-merror:0.26914\ttrain-merror:0.08629\n",
      "[7]\teval-merror:0.26960\ttrain-merror:0.08438\n",
      "[8]\teval-merror:0.26914\ttrain-merror:0.08284\n",
      "[9]\teval-merror:0.26869\ttrain-merror:0.08091\n",
      "[10]\teval-merror:0.26846\ttrain-merror:0.07798\n",
      "[11]\teval-merror:0.26823\ttrain-merror:0.07536\n",
      "[12]\teval-merror:0.26823\ttrain-merror:0.07402\n",
      "[13]\teval-merror:0.26869\ttrain-merror:0.07149\n",
      "[14]\teval-merror:0.26732\ttrain-merror:0.06972\n",
      "[15]\teval-merror:0.26664\ttrain-merror:0.06767\n",
      "[16]\teval-merror:0.26846\ttrain-merror:0.06651\n",
      "[17]\teval-merror:0.26892\ttrain-merror:0.06483\n",
      "[18]\teval-merror:0.26983\ttrain-merror:0.06295\n",
      "[19]\teval-merror:0.26983\ttrain-merror:0.06076\n",
      "[20]\teval-merror:0.27028\ttrain-merror:0.05908\n",
      "[21]\teval-merror:0.27165\ttrain-merror:0.05774\n",
      "[22]\teval-merror:0.27165\ttrain-merror:0.05638\n",
      "[23]\teval-merror:0.27028\ttrain-merror:0.05490\n",
      "[24]\teval-merror:0.27074\ttrain-merror:0.05316\n",
      "[25]\teval-merror:0.27119\ttrain-merror:0.05199\n",
      "[26]\teval-merror:0.27119\ttrain-merror:0.05100\n",
      "[27]\teval-merror:0.27188\ttrain-merror:0.04903\n",
      "[28]\teval-merror:0.27279\ttrain-merror:0.04767\n",
      "[29]\teval-merror:0.27165\ttrain-merror:0.04667\n",
      "[30]\teval-merror:0.27097\ttrain-merror:0.04582\n",
      "[31]\teval-merror:0.27165\ttrain-merror:0.04417\n",
      "[32]\teval-merror:0.27119\ttrain-merror:0.04346\n",
      "[33]\teval-merror:0.27028\ttrain-merror:0.04263\n",
      "[34]\teval-merror:0.27165\ttrain-merror:0.04186\n",
      "[35]\teval-merror:0.27051\ttrain-merror:0.04112\n",
      "[36]\teval-merror:0.27074\ttrain-merror:0.03976\n",
      "[37]\teval-merror:0.27005\ttrain-merror:0.03910\n",
      "[38]\teval-merror:0.27142\ttrain-merror:0.03816\n",
      "[39]\teval-merror:0.27142\ttrain-merror:0.03728\n",
      "[40]\teval-merror:0.27165\ttrain-merror:0.03648\n",
      "[41]\teval-merror:0.27302\ttrain-merror:0.03637\n",
      "[42]\teval-merror:0.27211\ttrain-merror:0.03560\n",
      "[43]\teval-merror:0.27256\ttrain-merror:0.03489\n",
      "[44]\teval-merror:0.27279\ttrain-merror:0.03478\n",
      "[45]\teval-merror:0.27393\ttrain-merror:0.03432\n",
      "[46]\teval-merror:0.27416\ttrain-merror:0.03347\n",
      "[47]\teval-merror:0.27530\ttrain-merror:0.03315\n",
      "[48]\teval-merror:0.27484\ttrain-merror:0.03247\n",
      "[49]\teval-merror:0.27644\ttrain-merror:0.03207\n",
      "[50]\teval-merror:0.27598\ttrain-merror:0.03167\n",
      "[51]\teval-merror:0.27712\ttrain-merror:0.03099\n",
      "[52]\teval-merror:0.27689\ttrain-merror:0.03082\n",
      "[53]\teval-merror:0.27780\ttrain-merror:0.03056\n",
      "[54]\teval-merror:0.27803\ttrain-merror:0.03019\n",
      "[55]\teval-merror:0.27917\ttrain-merror:0.02977\n",
      "[56]\teval-merror:0.27917\ttrain-merror:0.02948\n",
      "[57]\teval-merror:0.27826\ttrain-merror:0.02903\n",
      "[58]\teval-merror:0.27894\ttrain-merror:0.02843\n",
      "[59]\teval-merror:0.27894\ttrain-merror:0.02843\n",
      "[60]\teval-merror:0.27894\ttrain-merror:0.02792\n",
      "[61]\teval-merror:0.27894\ttrain-merror:0.02738\n",
      "[62]\teval-merror:0.27871\ttrain-merror:0.02715\n",
      "[63]\teval-merror:0.27917\ttrain-merror:0.02684\n",
      "[64]\teval-merror:0.27894\ttrain-merror:0.02650\n",
      "[65]\teval-merror:0.27780\ttrain-merror:0.02630\n",
      "[66]\teval-merror:0.27871\ttrain-merror:0.02590\n",
      "[67]\teval-merror:0.27826\ttrain-merror:0.02564\n",
      "[68]\teval-merror:0.27871\ttrain-merror:0.02530\n",
      "[69]\teval-merror:0.27917\ttrain-merror:0.02510\n",
      "[70]\teval-merror:0.27894\ttrain-merror:0.02487\n",
      "[71]\teval-merror:0.27871\ttrain-merror:0.02479\n",
      "[72]\teval-merror:0.27803\ttrain-merror:0.02453\n",
      "[73]\teval-merror:0.27826\ttrain-merror:0.02413\n",
      "[74]\teval-merror:0.27849\ttrain-merror:0.02402\n",
      "[75]\teval-merror:0.27894\ttrain-merror:0.02373\n",
      "[76]\teval-merror:0.27849\ttrain-merror:0.02348\n",
      "[77]\teval-merror:0.27940\ttrain-merror:0.02314\n",
      "[78]\teval-merror:0.27917\ttrain-merror:0.02297\n",
      "[79]\teval-merror:0.27940\ttrain-merror:0.02265\n",
      "[80]\teval-merror:0.27940\ttrain-merror:0.02260\n",
      "[81]\teval-merror:0.27917\ttrain-merror:0.02254\n",
      "[82]\teval-merror:0.27871\ttrain-merror:0.02248\n",
      "[83]\teval-merror:0.27826\ttrain-merror:0.02220\n",
      "[84]\teval-merror:0.27894\ttrain-merror:0.02194\n",
      "[85]\teval-merror:0.27871\ttrain-merror:0.02191\n",
      "[86]\teval-merror:0.27894\ttrain-merror:0.02166\n",
      "[87]\teval-merror:0.27894\ttrain-merror:0.02154\n",
      "[88]\teval-merror:0.27849\ttrain-merror:0.02132\n",
      "[89]\teval-merror:0.27780\ttrain-merror:0.02149\n",
      "[90]\teval-merror:0.27803\ttrain-merror:0.02129\n",
      "[91]\teval-merror:0.27826\ttrain-merror:0.02112\n",
      "[92]\teval-merror:0.27826\ttrain-merror:0.02109\n",
      "[93]\teval-merror:0.27894\ttrain-merror:0.02080\n",
      "[94]\teval-merror:0.27871\ttrain-merror:0.02080\n",
      "[95]\teval-merror:0.27849\ttrain-merror:0.02072\n",
      "[96]\teval-merror:0.27826\ttrain-merror:0.02066\n",
      "[97]\teval-merror:0.27849\ttrain-merror:0.02046\n",
      "[98]\teval-merror:0.27894\ttrain-merror:0.02035\n",
      "[99]\teval-merror:0.27871\ttrain-merror:0.02026\n",
      "[100]\teval-merror:0.27894\ttrain-merror:0.02009\n",
      "[101]\teval-merror:0.27894\ttrain-merror:0.01998\n",
      "[102]\teval-merror:0.27985\ttrain-merror:0.01998\n",
      "[103]\teval-merror:0.27940\ttrain-merror:0.01989\n",
      "[104]\teval-merror:0.27963\ttrain-merror:0.01978\n",
      "[105]\teval-merror:0.27940\ttrain-merror:0.01966\n",
      "[106]\teval-merror:0.27940\ttrain-merror:0.01958\n",
      "[107]\teval-merror:0.27940\ttrain-merror:0.01947\n",
      "[108]\teval-merror:0.27940\ttrain-merror:0.01932\n",
      "[109]\teval-merror:0.28008\ttrain-merror:0.01918\n",
      "[110]\teval-merror:0.28008\ttrain-merror:0.01921\n",
      "[111]\teval-merror:0.28008\ttrain-merror:0.01915\n",
      "[112]\teval-merror:0.27985\ttrain-merror:0.01907\n",
      "[113]\teval-merror:0.27963\ttrain-merror:0.01890\n",
      "[114]\teval-merror:0.27963\ttrain-merror:0.01890\n",
      "[115]\teval-merror:0.27963\ttrain-merror:0.01867\n",
      "[116]\teval-merror:0.28008\ttrain-merror:0.01861\n",
      "[117]\teval-merror:0.27871\ttrain-merror:0.01838\n",
      "[118]\teval-merror:0.27894\ttrain-merror:0.01836\n",
      "[119]\teval-merror:0.27963\ttrain-merror:0.01841\n",
      "[120]\teval-merror:0.27985\ttrain-merror:0.01821\n",
      "[121]\teval-merror:0.27963\ttrain-merror:0.01821\n",
      "[122]\teval-merror:0.27871\ttrain-merror:0.01810\n",
      "[123]\teval-merror:0.27894\ttrain-merror:0.01804\n",
      "[124]\teval-merror:0.27894\ttrain-merror:0.01787\n",
      "[125]\teval-merror:0.27917\ttrain-merror:0.01787\n",
      "[126]\teval-merror:0.27917\ttrain-merror:0.01790\n",
      "[127]\teval-merror:0.27894\ttrain-merror:0.01790\n",
      "[128]\teval-merror:0.27917\ttrain-merror:0.01776\n",
      "[129]\teval-merror:0.27917\ttrain-merror:0.01759\n",
      "[130]\teval-merror:0.27940\ttrain-merror:0.01767\n",
      "[131]\teval-merror:0.27940\ttrain-merror:0.01747\n",
      "[132]\teval-merror:0.27985\ttrain-merror:0.01739\n",
      "[133]\teval-merror:0.28008\ttrain-merror:0.01730\n",
      "[134]\teval-merror:0.28054\ttrain-merror:0.01719\n",
      "[135]\teval-merror:0.28099\ttrain-merror:0.01710\n",
      "[136]\teval-merror:0.28122\ttrain-merror:0.01693\n",
      "[137]\teval-merror:0.28099\ttrain-merror:0.01693\n",
      "[138]\teval-merror:0.28077\ttrain-merror:0.01688\n",
      "[139]\teval-merror:0.28077\ttrain-merror:0.01676\n",
      "[140]\teval-merror:0.28168\ttrain-merror:0.01679\n",
      "[141]\teval-merror:0.28168\ttrain-merror:0.01671\n",
      "[142]\teval-merror:0.28168\ttrain-merror:0.01676\n",
      "[143]\teval-merror:0.28213\ttrain-merror:0.01668\n",
      "[144]\teval-merror:0.28145\ttrain-merror:0.01653\n",
      "[145]\teval-merror:0.28168\ttrain-merror:0.01648\n",
      "[146]\teval-merror:0.28191\ttrain-merror:0.01645\n",
      "[147]\teval-merror:0.28191\ttrain-merror:0.01639\n",
      "[148]\teval-merror:0.28191\ttrain-merror:0.01616\n",
      "[149]\teval-merror:0.28122\ttrain-merror:0.01611\n",
      "[150]\teval-merror:0.28145\ttrain-merror:0.01608\n",
      "[151]\teval-merror:0.28099\ttrain-merror:0.01599\n",
      "[152]\teval-merror:0.28099\ttrain-merror:0.01597\n",
      "[153]\teval-merror:0.28077\ttrain-merror:0.01597\n",
      "[154]\teval-merror:0.28099\ttrain-merror:0.01591\n",
      "[155]\teval-merror:0.28145\ttrain-merror:0.01588\n",
      "[156]\teval-merror:0.28145\ttrain-merror:0.01591\n",
      "[157]\teval-merror:0.28168\ttrain-merror:0.01582\n",
      "[158]\teval-merror:0.28145\ttrain-merror:0.01559\n",
      "[159]\teval-merror:0.28145\ttrain-merror:0.01571\n",
      "[160]\teval-merror:0.28168\ttrain-merror:0.01551\n",
      "[161]\teval-merror:0.28168\ttrain-merror:0.01548\n",
      "[162]\teval-merror:0.28213\ttrain-merror:0.01537\n",
      "[163]\teval-merror:0.28191\ttrain-merror:0.01534\n",
      "[164]\teval-merror:0.28145\ttrain-merror:0.01520\n",
      "[165]\teval-merror:0.28145\ttrain-merror:0.01505\n",
      "[166]\teval-merror:0.28122\ttrain-merror:0.01505\n",
      "[167]\teval-merror:0.28122\ttrain-merror:0.01500\n",
      "[168]\teval-merror:0.28122\ttrain-merror:0.01494\n",
      "[169]\teval-merror:0.28145\ttrain-merror:0.01491\n",
      "[170]\teval-merror:0.28122\ttrain-merror:0.01480\n",
      "[171]\teval-merror:0.28099\ttrain-merror:0.01471\n",
      "[172]\teval-merror:0.28099\ttrain-merror:0.01460\n",
      "[173]\teval-merror:0.28099\ttrain-merror:0.01457\n",
      "[174]\teval-merror:0.28122\ttrain-merror:0.01451\n",
      "[175]\teval-merror:0.28077\ttrain-merror:0.01443\n",
      "[176]\teval-merror:0.28145\ttrain-merror:0.01443\n",
      "[177]\teval-merror:0.28077\ttrain-merror:0.01434\n",
      "[178]\teval-merror:0.28122\ttrain-merror:0.01417\n",
      "[179]\teval-merror:0.28168\ttrain-merror:0.01417\n",
      "[180]\teval-merror:0.28145\ttrain-merror:0.01417\n",
      "[181]\teval-merror:0.28191\ttrain-merror:0.01414\n",
      "[182]\teval-merror:0.28145\ttrain-merror:0.01403\n",
      "[183]\teval-merror:0.28122\ttrain-merror:0.01400\n",
      "[184]\teval-merror:0.28191\ttrain-merror:0.01392\n",
      "[185]\teval-merror:0.28145\ttrain-merror:0.01389\n",
      "[186]\teval-merror:0.28145\ttrain-merror:0.01389\n",
      "[187]\teval-merror:0.28168\ttrain-merror:0.01395\n",
      "[188]\teval-merror:0.28191\ttrain-merror:0.01383\n",
      "[189]\teval-merror:0.28213\ttrain-merror:0.01386\n",
      "[190]\teval-merror:0.28213\ttrain-merror:0.01366\n",
      "[191]\teval-merror:0.28236\ttrain-merror:0.01363\n",
      "[192]\teval-merror:0.28213\ttrain-merror:0.01358\n",
      "[193]\teval-merror:0.28259\ttrain-merror:0.01352\n",
      "[194]\teval-merror:0.28236\ttrain-merror:0.01349\n",
      "[195]\teval-merror:0.28236\ttrain-merror:0.01343\n",
      "[196]\teval-merror:0.28213\ttrain-merror:0.01340\n",
      "[197]\teval-merror:0.28191\ttrain-merror:0.01340\n",
      "[198]\teval-merror:0.28213\ttrain-merror:0.01329\n",
      "[199]\teval-merror:0.28213\ttrain-merror:0.01318\n",
      "[200]\teval-merror:0.28168\ttrain-merror:0.01292\n",
      "[201]\teval-merror:0.28168\ttrain-merror:0.01286\n",
      "[202]\teval-merror:0.28145\ttrain-merror:0.01303\n",
      "[203]\teval-merror:0.28145\ttrain-merror:0.01289\n",
      "[204]\teval-merror:0.28168\ttrain-merror:0.01300\n",
      "[205]\teval-merror:0.28213\ttrain-merror:0.01281\n",
      "[206]\teval-merror:0.28168\ttrain-merror:0.01272\n",
      "[207]\teval-merror:0.28191\ttrain-merror:0.01266\n",
      "[208]\teval-merror:0.28213\ttrain-merror:0.01269\n",
      "[209]\teval-merror:0.28191\ttrain-merror:0.01264\n",
      "[210]\teval-merror:0.28168\ttrain-merror:0.01252\n",
      "[211]\teval-merror:0.28168\ttrain-merror:0.01238\n",
      "[212]\teval-merror:0.28168\ttrain-merror:0.01232\n",
      "[213]\teval-merror:0.28168\ttrain-merror:0.01229\n",
      "[214]\teval-merror:0.28213\ttrain-merror:0.01218\n",
      "[215]\teval-merror:0.28213\ttrain-merror:0.01218\n",
      "[216]\teval-merror:0.28236\ttrain-merror:0.01209\n",
      "[217]\teval-merror:0.28168\ttrain-merror:0.01207\n",
      "[218]\teval-merror:0.28122\ttrain-merror:0.01207\n",
      "[219]\teval-merror:0.28168\ttrain-merror:0.01181\n",
      "[220]\teval-merror:0.28168\ttrain-merror:0.01175\n",
      "[221]\teval-merror:0.28213\ttrain-merror:0.01170\n",
      "[222]\teval-merror:0.28213\ttrain-merror:0.01170\n",
      "[223]\teval-merror:0.28236\ttrain-merror:0.01161\n",
      "[224]\teval-merror:0.28191\ttrain-merror:0.01155\n",
      "[225]\teval-merror:0.28191\ttrain-merror:0.01144\n",
      "[226]\teval-merror:0.28191\ttrain-merror:0.01147\n",
      "[227]\teval-merror:0.28213\ttrain-merror:0.01147\n",
      "[228]\teval-merror:0.28236\ttrain-merror:0.01141\n",
      "[229]\teval-merror:0.28168\ttrain-merror:0.01136\n",
      "[230]\teval-merror:0.28168\ttrain-merror:0.01130\n",
      "[231]\teval-merror:0.28168\ttrain-merror:0.01118\n",
      "[232]\teval-merror:0.28145\ttrain-merror:0.01116\n",
      "[233]\teval-merror:0.28122\ttrain-merror:0.01104\n",
      "[234]\teval-merror:0.28145\ttrain-merror:0.01107\n",
      "[235]\teval-merror:0.28099\ttrain-merror:0.01107\n",
      "[236]\teval-merror:0.28099\ttrain-merror:0.01113\n",
      "[237]\teval-merror:0.28077\ttrain-merror:0.01110\n",
      "[238]\teval-merror:0.28077\ttrain-merror:0.01098\n",
      "[239]\teval-merror:0.28031\ttrain-merror:0.01104\n",
      "[240]\teval-merror:0.28008\ttrain-merror:0.01096\n",
      "[241]\teval-merror:0.27985\ttrain-merror:0.01098\n",
      "[242]\teval-merror:0.27985\ttrain-merror:0.01090\n",
      "[243]\teval-merror:0.28008\ttrain-merror:0.01067\n",
      "[244]\teval-merror:0.28031\ttrain-merror:0.01064\n",
      "[245]\teval-merror:0.28008\ttrain-merror:0.01070\n",
      "[246]\teval-merror:0.28008\ttrain-merror:0.01073\n",
      "[247]\teval-merror:0.28031\ttrain-merror:0.01070\n",
      "[248]\teval-merror:0.28031\ttrain-merror:0.01050\n",
      "[249]\teval-merror:0.28031\ttrain-merror:0.01042\n",
      "[250]\teval-merror:0.28008\ttrain-merror:0.01039\n",
      "[251]\teval-merror:0.28054\ttrain-merror:0.01033\n",
      "[252]\teval-merror:0.28054\ttrain-merror:0.01033\n",
      "[253]\teval-merror:0.28077\ttrain-merror:0.01027\n",
      "[254]\teval-merror:0.28077\ttrain-merror:0.01030\n",
      "[255]\teval-merror:0.28054\ttrain-merror:0.01033\n",
      "[256]\teval-merror:0.28122\ttrain-merror:0.01030\n",
      "[257]\teval-merror:0.28145\ttrain-merror:0.01022\n",
      "[258]\teval-merror:0.28122\ttrain-merror:0.01007\n",
      "[259]\teval-merror:0.28077\ttrain-merror:0.01002\n",
      "[260]\teval-merror:0.28077\ttrain-merror:0.00993\n",
      "[261]\teval-merror:0.28077\ttrain-merror:0.00993\n",
      "[262]\teval-merror:0.28077\ttrain-merror:0.00988\n",
      "[263]\teval-merror:0.28077\ttrain-merror:0.00985\n",
      "[264]\teval-merror:0.28054\ttrain-merror:0.00979\n",
      "[265]\teval-merror:0.28054\ttrain-merror:0.00979\n",
      "[266]\teval-merror:0.28099\ttrain-merror:0.00985\n",
      "[267]\teval-merror:0.28099\ttrain-merror:0.00985\n",
      "[268]\teval-merror:0.28077\ttrain-merror:0.00973\n",
      "[269]\teval-merror:0.28054\ttrain-merror:0.00968\n",
      "[270]\teval-merror:0.28054\ttrain-merror:0.00965\n",
      "[271]\teval-merror:0.28099\ttrain-merror:0.00962\n",
      "[272]\teval-merror:0.28054\ttrain-merror:0.00953\n",
      "[273]\teval-merror:0.28099\ttrain-merror:0.00956\n",
      "[274]\teval-merror:0.28077\ttrain-merror:0.00953\n",
      "[275]\teval-merror:0.28054\ttrain-merror:0.00939\n",
      "[276]\teval-merror:0.28077\ttrain-merror:0.00933\n",
      "[277]\teval-merror:0.27985\ttrain-merror:0.00928\n",
      "[278]\teval-merror:0.28054\ttrain-merror:0.00933\n",
      "[279]\teval-merror:0.28054\ttrain-merror:0.00925\n",
      "[280]\teval-merror:0.28077\ttrain-merror:0.00908\n",
      "[281]\teval-merror:0.28099\ttrain-merror:0.00911\n",
      "[282]\teval-merror:0.28099\ttrain-merror:0.00908\n",
      "[283]\teval-merror:0.28054\ttrain-merror:0.00908\n",
      "[284]\teval-merror:0.28008\ttrain-merror:0.00902\n",
      "[285]\teval-merror:0.28054\ttrain-merror:0.00894\n",
      "[286]\teval-merror:0.28031\ttrain-merror:0.00899\n",
      "[287]\teval-merror:0.28054\ttrain-merror:0.00882\n",
      "[288]\teval-merror:0.28054\ttrain-merror:0.00871\n",
      "[289]\teval-merror:0.28031\ttrain-merror:0.00871\n",
      "[290]\teval-merror:0.28054\ttrain-merror:0.00874\n",
      "[291]\teval-merror:0.28031\ttrain-merror:0.00868\n",
      "[292]\teval-merror:0.28008\ttrain-merror:0.00859\n",
      "[293]\teval-merror:0.28008\ttrain-merror:0.00862\n",
      "[294]\teval-merror:0.28031\ttrain-merror:0.00854\n",
      "[295]\teval-merror:0.28031\ttrain-merror:0.00839\n",
      "[296]\teval-merror:0.28008\ttrain-merror:0.00837\n",
      "[297]\teval-merror:0.28008\ttrain-merror:0.00834\n",
      "[298]\teval-merror:0.28031\ttrain-merror:0.00834\n",
      "[299]\teval-merror:0.28054\ttrain-merror:0.00831\n"
     ]
    }
   ],
   "source": [
    "import xgboost as xgb\n",
    "dtrain = xgb.DMatrix(x_dense_train, label=y_train)\n",
    "dtest = xgb.DMatrix(x_dense_test, label=y_test)\n",
    "param = {'max_depth':4 , 'eta': 0.15, 'objective': 'multi:softprob','lambda':1.5,'num_class':6}\n",
    "param['nthread'] = 15\n",
    "param['eval_metric'] = 'merror'\n",
    "\n",
    "evallist = [(dtest, 'eval'), (dtrain, 'train')]\n",
    "\n",
    "num_round = 300\n",
    "bst = xgb.train(param, dtrain, num_round, evallist)\n",
    "\n",
    "#ypred = bst.predict(x_testf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.83      0.85      3377\n",
      "           1       0.26      0.27      0.27       286\n",
      "           2       0.22      0.28      0.25       246\n",
      "           3       0.02      0.06      0.02        17\n",
      "           4       0.28      0.31      0.29       323\n",
      "           5       0.68      0.84      0.75       139\n",
      "\n",
      "    accuracy                           0.72      4388\n",
      "   macro avg       0.39      0.43      0.41      4388\n",
      "weighted avg       0.75      0.72      0.73      4388\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "ypred = bst.predict(xgb.DMatrix(x_dense_test))\n",
    "prediction = []\n",
    "for i,j in enumerate(ypred):\n",
    "    a = np.argmax(j)\n",
    "    prediction.append(a)\n",
    "\n",
    "print(classification_report(prediction, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**RANDOM FOREST**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.81      0.86      3578\n",
      "           1       0.25      0.32      0.28       230\n",
      "           2       0.19      0.32      0.24       185\n",
      "           3       0.00      0.00      0.00         8\n",
      "           4       0.23      0.32      0.27       250\n",
      "           5       0.68      0.85      0.76       137\n",
      "\n",
      "    accuracy                           0.74      4388\n",
      "   macro avg       0.38      0.44      0.40      4388\n",
      "weighted avg       0.80      0.74      0.76      4388\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "clf = RandomForestClassifier(max_depth=30, random_state=5,n_estimators = 500 )\n",
    "clf.fit(x_dense_train, y_train)\n",
    "pred = clf.predict(x_dense_test)\n",
    "\n",
    "print(classification_report(pred, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**SVM**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.83      0.85      3344\n",
      "           1       0.26      0.27      0.27       287\n",
      "           2       0.22      0.28      0.25       244\n",
      "           3       0.02      0.04      0.02        25\n",
      "           4       0.30      0.32      0.31       339\n",
      "           5       0.69      0.80      0.74       149\n",
      "\n",
      "    accuracy                           0.72      4388\n",
      "   macro avg       0.39      0.42      0.41      4388\n",
      "weighted avg       0.74      0.72      0.73      4388\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn import svm\n",
    "clf = svm.SVC()\n",
    "clf.fit(x_dense_train, y_train)\n",
    "pred = clf.predict(x_dense_test)\n",
    "\n",
    "print(classification_report(pred, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**LOGISTIC REGRESSION**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.83      0.85      3346\n",
      "           1       0.26      0.27      0.27       291\n",
      "           2       0.22      0.27      0.24       252\n",
      "           3       0.02      0.03      0.02        29\n",
      "           4       0.29      0.31      0.30       328\n",
      "           5       0.68      0.82      0.75       142\n",
      "\n",
      "    accuracy                           0.72      4388\n",
      "   macro avg       0.39      0.42      0.40      4388\n",
      "weighted avg       0.74      0.72      0.73      4388\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/punyajoy/.conda/envs/nlp/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "clf = LogisticRegression()\n",
    "clf.fit(x_dense_train, y_train)\n",
    "pred = clf.predict(x_dense_test)\n",
    "\n",
    "print(classification_report(pred, y_test))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:.conda-nlp]",
   "language": "python",
   "name": "conda-env-.conda-nlp-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
