{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Imports and Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading CSV from link\n",
    "def read_csv_from_link(url):\n",
    "    path = 'https://drive.google.com/uc?export=download&id='+url.split('/')[-2]\n",
    "    df = pd.read_csv(path,delimiter=\"\\t\",error_bad_lines=False, header=None)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading All Data\n",
    "tamil_train = read_csv_from_link('https://drive.google.com/file/d/15auwrFAlq52JJ61u7eSfnhT9rZtI5sjk/view?usp=sharing')\n",
    "tamil_dev = read_csv_from_link('https://drive.google.com/file/d/1Jme-Oftjm7OgfMNLKQs1mO_cnsQmznRI/view?usp=sharing')\n",
    "malayalam_train = read_csv_from_link('https://drive.google.com/file/d/13JCCr-IjZK7uhbLXeufptr_AxvsKinVl/view?usp=sharing')\n",
    "malayalam_dev = read_csv_from_link('https://drive.google.com/file/d/1J0msLpLoM6gmXkjC6DFeQ8CG_rrLvjnM/view?usp=sharing')\n",
    "kannada_train = read_csv_from_link('https://drive.google.com/file/d/1BFYF05rx-DK9Eb5hgoIgd6EcB8zOI-zu/view?usp=sharing')\n",
    "kannada_dev = read_csv_from_link('https://drive.google.com/file/d/1V077dMQvscqpUmcWTcFHqRa_vTy-bQ4H/view?usp=sharing')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mal Preprocess\n",
    "kannada_train = kannada_train.iloc[:, 0:2]\n",
    "kannada_train = kannada_train.rename(columns={0: \"text\", 1: \"label\"})\n",
    "# Stats\n",
    "kannada_train['label'] = pd.Categorical(kannada_train.label)\n",
    "# Mal Preprocess\n",
    "kannada_dev = kannada_dev.iloc[:, 0:2]\n",
    "kannada_dev = kannada_dev.rename(columns={0: \"text\", 1: \"label\"})\n",
    "# Stats\n",
    "kannada_dev['label'] = pd.Categorical(kannada_dev.label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU Nos: 2\n",
      "Tesla P100-PCIE-12GB\n",
      "Tesla P100-PCIE-16GB\n"
     ]
    }
   ],
   "source": [
    "print(\"GPU Nos: {}\".format(torch.cuda.device_count()))\n",
    "print(torch.cuda.get_device_name(0))\n",
    "print(torch.cuda.get_device_name(1))\n",
    "\n",
    "# Change Device - CPU/GPU-0/GPU-1\n",
    "torch.cuda.set_device(0)\n",
    "device = 'cuda'\n",
    "device = device if torch.cuda.is_available() else 'cpu'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Enter Path of Saved model here in torch.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "saved_model_filenames = [\n",
    "    'XLMroberta_large_kannada.pth',\n",
    "    'MURIL_cased_temp_kannada.pth',\n",
    "    'Indic_bert_kannada.pth',\n",
    "    'Indic_bert_kannada_weighted.pth',\n",
    "    'MURIL_cased_temp_kannada_weighted.pth',\n",
    "    'XLMroberta_large_kannada_weighted.pth',\n",
    "    'Mbert_base_cased_kannada.pth',\n",
    "    'Distilbert_m_base_cased_kannada.pth',\n",
    "    'XLMroberta_custom_pretrained_kannada.pth',\n",
    "    'Mbert_base_cased_kannada_weighted.pth',\n",
    "    'Distilbert_m_base_cased_kannada_weighted.pth',\n",
    "    'XLMroberta_custom_pretrained_kannada_weighted.pth'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_pretrained_keys = [\n",
    "    'xlm-roberta-large',\n",
    "    \"simran-kh/muril-cased-temp\",\n",
    "    'ai4bharat/indic-bert',\n",
    "    'ai4bharat/indic-bert',\n",
    "    \"simran-kh/muril-cased-temp\",\n",
    "    'xlm-roberta-large',\n",
    "    'bert-base-multilingual-cased',\n",
    "    'distilbert-base-multilingual-cased',\n",
    "    'xlm-roberta-base',\n",
    "    'bert-base-multilingual-cased',\n",
    "    'distilbert-base-multilingual-cased',\n",
    "    'xlm-roberta-base',\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizers = []\n",
    "models = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at xlm-roberta-large were not used when initializing XLMRobertaForSequenceClassification: ['lm_head.bias', 'lm_head.dense.weight', 'lm_head.dense.bias', 'lm_head.layer_norm.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']\n",
      "- This IS expected if you are initializing XLMRobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of XLMRobertaForSequenceClassification were not initialized from the model checkpoint at xlm-roberta-large and are newly initialized: ['classifier.dense.weight', 'classifier.dense.bias', 'classifier.out_proj.weight', 'classifier.out_proj.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of the model checkpoint at simran-kh/muril-cased-temp were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.predictions.decoder.bias', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at simran-kh/muril-cased-temp and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of the model checkpoint at ai4bharat/indic-bert were not used when initializing AlbertForSequenceClassification: ['predictions.bias', 'predictions.LayerNorm.weight', 'predictions.LayerNorm.bias', 'predictions.dense.weight', 'predictions.dense.bias', 'predictions.decoder.weight', 'predictions.decoder.bias', 'sop_classifier.classifier.weight', 'sop_classifier.classifier.bias']\n",
      "- This IS expected if you are initializing AlbertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing AlbertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of AlbertForSequenceClassification were not initialized from the model checkpoint at ai4bharat/indic-bert and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of the model checkpoint at ai4bharat/indic-bert were not used when initializing AlbertForSequenceClassification: ['predictions.bias', 'predictions.LayerNorm.weight', 'predictions.LayerNorm.bias', 'predictions.dense.weight', 'predictions.dense.bias', 'predictions.decoder.weight', 'predictions.decoder.bias', 'sop_classifier.classifier.weight', 'sop_classifier.classifier.bias']\n",
      "- This IS expected if you are initializing AlbertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing AlbertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of AlbertForSequenceClassification were not initialized from the model checkpoint at ai4bharat/indic-bert and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "# Loading Model\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, BertTokenizer, BertForSequenceClassification\n",
    "\n",
    "for model_name, pretrained_key in zip(saved_model_filenames, model_pretrained_keys):\n",
    "    \n",
    "    if pretrained_key == 'distilbert-base-multilingual-cased':\n",
    "        tokenizer = BertTokenizer.from_pretrained(pretrained_key)\n",
    "        model = BertForSequenceClassification.from_pretrained(pretrained_key, num_labels=6)\n",
    "    else:\n",
    "        tokenizer = AutoTokenizer.from_pretrained(pretrained_key)\n",
    "        model = AutoModelForSequenceClassification.from_pretrained(pretrained_key, num_labels=6)\n",
    "        \n",
    "    state_dict = torch.load(os.path.join('../../finetuned_models/', model_name))\n",
    "    model.load_state_dict(state_dict)\n",
    "    model.eval()\n",
    "    \n",
    "    models.append(model)\n",
    "    tokenizers.append(tokenizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset Stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'tokenizers' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-c3d38e38ad75>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;31m# Convert to Tensor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m \u001b[0mtrain_encodings\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mtokenizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_batch_sentences\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpadding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'max_length'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtruncation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_length\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m64\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_tensors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"pt\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mtokenizer\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtokenizers\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m \u001b[0mtrain_labels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_batch_labels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0mdev_encodings\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mtokenizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdev_batch_sentences\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpadding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'max_length'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtruncation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_length\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m64\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_tensors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"pt\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mtokenizer\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtokenizers\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'tokenizers' is not defined"
     ]
    }
   ],
   "source": [
    "label_mapping = {\n",
    "    'Not_offensive': 0, \n",
    "    'not-Kannada': 1, \n",
    "    'Offensive_Targeted_Insult_Other': 2, \n",
    "    'Offensive_Targeted_Insult_Group': 3, \n",
    "    'Offensive_Untargetede': 4, \n",
    "    'Offensive_Targeted_Insult_Individual': 5\n",
    "}\n",
    "\n",
    "# Collecting Text and Labels\n",
    "train_batch_sentences = list(kannada_train['text'])\n",
    "train_batch_labels =  [label_mapping[x] for x in kannada_train['label']]\n",
    "dev_batch_sentences = list(kannada_dev['text'])\n",
    "dev_batch_labels =  [label_mapping[x] for x in kannada_dev['label']]\n",
    "\n",
    "# Convert to Tensor\n",
    "train_encodings = [tokenizer(train_batch_sentences, padding='max_length', truncation=True, max_length=64, return_tensors=\"pt\") for tokenizer in tokenizers]\n",
    "train_labels = torch.tensor(train_batch_labels)\n",
    "dev_encodings = [tokenizer(dev_batch_sentences, padding='max_length', truncation=True, max_length=64, return_tensors=\"pt\") for tokenizer in tokenizers]\n",
    "dev_labels = torch.tensor(dev_batch_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "class Kannada_Offensive_Dataset(Dataset):\n",
    "    def __init__(self, encodings, labels, bpe = False):\n",
    "        self.encodings = encodings\n",
    "        self.labels = labels\n",
    "        self.is_bpe_tokenized = bpe\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if not self.is_bpe_tokenized:\n",
    "            item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
    "        else:\n",
    "            item = {\n",
    "                'input_ids': torch.LongTensor(self.encodings[idx].ids),\n",
    "                'attention_mask': torch.LongTensor(self.encodings[idx].attention_mask)\n",
    "            }\n",
    "        item['labels'] = torch.tensor(self.labels[idx])\n",
    "        return item\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "    \n",
    "# Defining Datasets\n",
    "train_datasets = [Kannada_Offensive_Dataset(tenc, train_labels, bpe = False) for tenc in train_encodings]\n",
    "dev_datasets = [Kannada_Offensive_Dataset(denc, dev_labels, bpe = False) for denc in dev_encodings]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5aa4d820cb144b32bf9600b36f314ce3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=4.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "888f121f3d374b5c8fcc7f2908f333eb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=49.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/punyajoy/.conda/envs/nlp/lib/python3.7/site-packages/ipykernel_launcher.py:12: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if sys.path[0] == '':\n",
      "/home/punyajoy/.conda/envs/nlp/lib/python3.7/site-packages/ipykernel_launcher.py:18: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "784b588465f44f809b8cb3c649f7303a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=49.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3cf2a680d3514d2b856a05dcf8e665ac",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=49.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9a16af902ec347e0a1b4a807ebaca3dc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=49.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "from tqdm.notebook import tqdm\n",
    "from sklearn.metrics import classification_report, f1_score\n",
    "\n",
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "all_dev_preds = []\n",
    "\n",
    "for model, dev_dataset in tqdm(zip(models, dev_datasets), total = len(models)):\n",
    "    model.to(device)\n",
    "    # Dataloaders\n",
    "    dev_loader = DataLoader(dev_dataset, batch_size=16, shuffle=False)\n",
    "\n",
    "    dev_preds = []\n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(dev_loader):\n",
    "            input_ids = batch['input_ids'].to(device)\n",
    "            attention_mask = batch['attention_mask'].to(device)\n",
    "            labels = batch['labels'].to(device)\n",
    "            outputs = model(input_ids, attention_mask=attention_mask, labels=labels)\n",
    "\n",
    "            for logits in outputs[1].cpu().numpy():\n",
    "                dev_preds.append(np.exp(logits)/np.sum(np.exp(logits)))\n",
    "    \n",
    "    # Add All together\n",
    "    all_dev_preds.append(dev_preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SAVE PREDS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "for dev_preds, modelname in zip(all_dev_preds, saved_model_filenames):\n",
    "    np.save('../../model_prediction_probs/preds_'+modelname+'.npy', dev_preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_pretrained_keys = [\n",
    "    'xlm-roberta-base',\n",
    "    'distilbert-base-multilingual-cased',\n",
    "    'ai4bharat/indic-bert',\n",
    "    'distilbert-base-multilingual-cased',\n",
    "    'xlm-roberta-base',\n",
    "    \"simran-kh/muril-cased-temp\",\n",
    "    'xlm-roberta-large',    \n",
    "    'bert-base-multilingual-cased',\n",
    "    'bert-base-multilingual-cased',\n",
    "    'xlm-roberta-large',\n",
    "    'ai4bharat/indic-bert',\n",
    "    \"simran-kh/muril-cased-temp\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "a = [x for x in os.listdir('../../model_prediction_probs/') if 'anna' in x and 'llate' not in x and 'only' not in x and 'fusion' not in x and x.startswith('pre') and 'self' not in x]\n",
    "len(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12\n"
     ]
    }
   ],
   "source": [
    "load_model_filenames = [\n",
    "    'XLMroberta_custom_pretrained_kannada.pth',\n",
    "    'Distilbert_m_base_cased_kannada_weighted.pth',\n",
    "    'Indic_bert_kannada_weighted.pth',\n",
    "    'Distilbert_m_base_cased_kannada.pth',\n",
    "    'XLMroberta_custom_pretrained_kannada_weighted.pth',\n",
    "    'MURIL_cased_temp_kannada.pth',\n",
    "    'XLMroberta_large_kannada_weighted.pth',\n",
    "    'Mbert_base_cased_kannada.pth',\n",
    "    'Mbert_base_cased_kannada_weighted.pth',\n",
    "    'XLMroberta_large_kannada.pth',\n",
    "    'Indic_bert_kannada.pth',\n",
    "    'MURIL_cased_temp_kannada_weighted.pth',\n",
    "]\n",
    "\n",
    "model_pretrained_keys = [\n",
    "    'xlm-roberta-base',\n",
    "    'distilbert-base-multilingual-cased',\n",
    "    'ai4bharat/indic-bert',\n",
    "    'distilbert-base-multilingual-cased',\n",
    "    'xlm-roberta-base',\n",
    "    \"simran-kh/muril-cased-temp\",\n",
    "    'xlm-roberta-large',    \n",
    "    'bert-base-multilingual-cased',\n",
    "    'bert-base-multilingual-cased',\n",
    "    'xlm-roberta-large',\n",
    "    'ai4bharat/indic-bert',\n",
    "    \"simran-kh/muril-cased-temp\",\n",
    "]\n",
    "\n",
    "print(len(load_model_filenames))\n",
    "\n",
    "all_dev_preds = []\n",
    "for modelname in load_model_filenames:\n",
    "    all_dev_preds.append(np.load('../../model_prediction_probs/preds_'+modelname+'.npy'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XLMroberta_custom_pretrained_kannada.pth\n",
      "                                      precision    recall  f1-score   support\n",
      "\n",
      "                       Not_offensive       0.79      0.80      0.80       426\n",
      "                         not-Kannada       0.74      0.81      0.77       191\n",
      "     Offensive_Targeted_Insult_Other       0.00      0.00      0.00        16\n",
      "     Offensive_Targeted_Insult_Group       0.37      0.49      0.42        45\n",
      "               Offensive_Untargetede       0.05      0.03      0.04        33\n",
      "Offensive_Targeted_Insult_Individual       0.63      0.59      0.61        66\n",
      "\n",
      "                            accuracy                           0.72       777\n",
      "                           macro avg       0.43      0.45      0.44       777\n",
      "                        weighted avg       0.69      0.72      0.70       777\n",
      "\n",
      "Distilbert_m_base_cased_kannada_weighted.pth\n",
      "                                      precision    recall  f1-score   support\n",
      "\n",
      "                       Not_offensive       0.77      0.76      0.76       426\n",
      "                         not-Kannada       0.74      0.69      0.71       191\n",
      "     Offensive_Targeted_Insult_Other       0.00      0.00      0.00        16\n",
      "     Offensive_Targeted_Insult_Group       0.29      0.38      0.33        45\n",
      "               Offensive_Untargetede       0.10      0.12      0.11        33\n",
      "Offensive_Targeted_Insult_Individual       0.57      0.62      0.59        66\n",
      "\n",
      "                            accuracy                           0.66       777\n",
      "                           macro avg       0.41      0.43      0.42       777\n",
      "                        weighted avg       0.67      0.66      0.67       777\n",
      "\n",
      "Indic_bert_kannada_weighted.pth\n",
      "                                      precision    recall  f1-score   support\n",
      "\n",
      "                       Not_offensive       0.78      0.46      0.58       426\n",
      "                         not-Kannada       0.67      0.83      0.74       191\n",
      "     Offensive_Targeted_Insult_Other       0.12      0.06      0.08        16\n",
      "     Offensive_Targeted_Insult_Group       0.20      0.60      0.30        45\n",
      "               Offensive_Untargetede       0.10      0.15      0.12        33\n",
      "Offensive_Targeted_Insult_Individual       0.32      0.47      0.38        66\n",
      "\n",
      "                            accuracy                           0.54       777\n",
      "                           macro avg       0.37      0.43      0.37       777\n",
      "                        weighted avg       0.64      0.54      0.56       777\n",
      "\n",
      "Distilbert_m_base_cased_kannada.pth\n",
      "                                      precision    recall  f1-score   support\n",
      "\n",
      "                       Not_offensive       0.77      0.80      0.78       426\n",
      "                         not-Kannada       0.70      0.78      0.74       191\n",
      "     Offensive_Targeted_Insult_Other       0.00      0.00      0.00        16\n",
      "     Offensive_Targeted_Insult_Group       0.41      0.20      0.27        45\n",
      "               Offensive_Untargetede       0.27      0.09      0.14        33\n",
      "Offensive_Targeted_Insult_Individual       0.49      0.67      0.57        66\n",
      "\n",
      "                            accuracy                           0.70       777\n",
      "                           macro avg       0.44      0.42      0.42       777\n",
      "                        weighted avg       0.67      0.70      0.68       777\n",
      "\n",
      "XLMroberta_custom_pretrained_kannada_weighted.pth\n",
      "                                      precision    recall  f1-score   support\n",
      "\n",
      "                       Not_offensive       0.78      0.74      0.76       426\n",
      "                         not-Kannada       0.69      0.80      0.74       191\n",
      "     Offensive_Targeted_Insult_Other       0.21      0.31      0.25        16\n",
      "     Offensive_Targeted_Insult_Group       0.45      0.22      0.30        45\n",
      "               Offensive_Untargetede       0.19      0.15      0.17        33\n",
      "Offensive_Targeted_Insult_Individual       0.51      0.59      0.55        66\n",
      "\n",
      "                            accuracy                           0.68       777\n",
      "                           macro avg       0.47      0.47      0.46       777\n",
      "                        weighted avg       0.68      0.68      0.67       777\n",
      "\n",
      "MURIL_cased_temp_kannada.pth\n",
      "                                      precision    recall  f1-score   support\n",
      "\n",
      "                       Not_offensive       0.77      0.76      0.76       426\n",
      "                         not-Kannada       0.68      0.76      0.72       191\n",
      "     Offensive_Targeted_Insult_Other       1.00      0.06      0.12        16\n",
      "     Offensive_Targeted_Insult_Group       0.40      0.27      0.32        45\n",
      "               Offensive_Untargetede       0.15      0.24      0.18        33\n",
      "Offensive_Targeted_Insult_Individual       0.56      0.50      0.53        66\n",
      "\n",
      "                            accuracy                           0.67       777\n",
      "                           macro avg       0.59      0.43      0.44       777\n",
      "                        weighted avg       0.69      0.67      0.67       777\n",
      "\n",
      "XLMroberta_large_kannada_weighted.pth\n",
      "                                      precision    recall  f1-score   support\n",
      "\n",
      "                       Not_offensive       0.50      0.00      0.00       426\n",
      "                         not-Kannada       0.73      0.14      0.24       191\n",
      "     Offensive_Targeted_Insult_Other       0.02      0.94      0.05        16\n",
      "     Offensive_Targeted_Insult_Group       0.00      0.00      0.00        45\n",
      "               Offensive_Untargetede       0.03      0.09      0.04        33\n",
      "Offensive_Targeted_Insult_Individual       0.00      0.00      0.00        66\n",
      "\n",
      "                            accuracy                           0.06       777\n",
      "                           macro avg       0.21      0.20      0.06       777\n",
      "                        weighted avg       0.46      0.06      0.06       777\n",
      "\n",
      "Mbert_base_cased_kannada.pth\n",
      "                                      precision    recall  f1-score   support\n",
      "\n",
      "                       Not_offensive       0.73      0.86      0.79       426\n",
      "                         not-Kannada       0.73      0.72      0.72       191\n",
      "     Offensive_Targeted_Insult_Other       1.00      0.06      0.12        16\n",
      "     Offensive_Targeted_Insult_Group       0.48      0.31      0.38        45\n",
      "               Offensive_Untargetede       0.28      0.15      0.20        33\n",
      "Offensive_Targeted_Insult_Individual       0.72      0.47      0.57        66\n",
      "\n",
      "                            accuracy                           0.71       777\n",
      "                           macro avg       0.66      0.43      0.46       777\n",
      "                        weighted avg       0.70      0.71      0.69       777\n",
      "\n",
      "Mbert_base_cased_kannada_weighted.pth\n",
      "                                      precision    recall  f1-score   support\n",
      "\n",
      "                       Not_offensive       0.79      0.64      0.71       426\n",
      "                         not-Kannada       0.71      0.80      0.75       191\n",
      "     Offensive_Targeted_Insult_Other       0.16      0.31      0.21        16\n",
      "     Offensive_Targeted_Insult_Group       0.26      0.36      0.30        45\n",
      "               Offensive_Untargetede       0.10      0.09      0.10        33\n",
      "Offensive_Targeted_Insult_Individual       0.46      0.65      0.54        66\n",
      "\n",
      "                            accuracy                           0.64       777\n",
      "                           macro avg       0.41      0.48      0.43       777\n",
      "                        weighted avg       0.67      0.64      0.65       777\n",
      "\n",
      "XLMroberta_large_kannada.pth\n",
      "                                      precision    recall  f1-score   support\n",
      "\n",
      "                       Not_offensive       0.76      0.84      0.80       426\n",
      "                         not-Kannada       0.71      0.85      0.78       191\n",
      "     Offensive_Targeted_Insult_Other       0.00      0.00      0.00        16\n",
      "     Offensive_Targeted_Insult_Group       0.29      0.31      0.30        45\n",
      "               Offensive_Untargetede       0.00      0.00      0.00        33\n",
      "Offensive_Targeted_Insult_Individual       0.74      0.35      0.47        66\n",
      "\n",
      "                            accuracy                           0.72       777\n",
      "                           macro avg       0.42      0.39      0.39       777\n",
      "                        weighted avg       0.67      0.72      0.69       777\n",
      "\n",
      "Indic_bert_kannada.pth\n",
      "                                      precision    recall  f1-score   support\n",
      "\n",
      "                       Not_offensive       0.70      0.76      0.73       426\n",
      "                         not-Kannada       0.71      0.70      0.71       191\n",
      "     Offensive_Targeted_Insult_Other       0.00      0.00      0.00        16\n",
      "     Offensive_Targeted_Insult_Group       0.19      0.33      0.25        45\n",
      "               Offensive_Untargetede       0.00      0.00      0.00        33\n",
      "Offensive_Targeted_Insult_Individual       0.45      0.36      0.40        66\n",
      "\n",
      "                            accuracy                           0.64       777\n",
      "                           macro avg       0.34      0.36      0.35       777\n",
      "                        weighted avg       0.61      0.64      0.62       777\n",
      "\n",
      "MURIL_cased_temp_kannada_weighted.pth\n",
      "                                      precision    recall  f1-score   support\n",
      "\n",
      "                       Not_offensive       0.83      0.55      0.67       426\n",
      "                         not-Kannada       0.65      0.81      0.72       191\n",
      "     Offensive_Targeted_Insult_Other       0.22      0.12      0.16        16\n",
      "     Offensive_Targeted_Insult_Group       0.20      0.27      0.23        45\n",
      "               Offensive_Untargetede       0.13      0.36      0.19        33\n",
      "Offensive_Targeted_Insult_Individual       0.48      0.65      0.55        66\n",
      "\n",
      "                            accuracy                           0.59       777\n",
      "                           macro avg       0.42      0.46      0.42       777\n",
      "                        weighted avg       0.68      0.59      0.61       777\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/punyajoy/.conda/envs/nlp/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "label_mapping = {\n",
    "    'Not_offensive': 0, \n",
    "    'not-Kannada': 1, \n",
    "    'Offensive_Targeted_Insult_Other': 2, \n",
    "    'Offensive_Targeted_Insult_Group': 3, \n",
    "    'Offensive_Untargetede': 4, \n",
    "    'Offensive_Targeted_Insult_Individual': 5\n",
    "}\n",
    "\n",
    "# Collecting Text and Labels\n",
    "train_batch_sentences = list(kannada_train['text'])\n",
    "train_batch_labels =  [label_mapping[x] for x in kannada_train['label']]\n",
    "dev_batch_sentences = list(kannada_dev['text'])\n",
    "dev_batch_labels =  [label_mapping[x] for x in kannada_dev['label']]\n",
    "\n",
    "for dev_preds, mn in zip(all_dev_preds, load_model_filenames):\n",
    "    final_dev_preds = np.argmax(dev_preds, axis = 1)\n",
    "    y_true = dev_batch_labels\n",
    "    y_pred = final_dev_preds\n",
    "    target_names = label_mapping.keys()\n",
    "    report = classification_report(y_true, y_pred, target_names=target_names)\n",
    "    print(mn)\n",
    "    print(report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Averaging Ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_dev_preds = np.array(all_dev_preds)\n",
    "\n",
    "# Initialise Weights\n",
    "w = np.ones(all_dev_preds.shape[0])\n",
    "softmax_w = np.exp(w)/np.sum(np.exp(w))\n",
    "\n",
    "weighted_all_dev_preds = np.array([sw*dpreds for sw, dpreds in zip(softmax_w, all_dev_preds)])\n",
    "weighted_dev_preds = np.sum(weighted_all_dev_preds, axis = 0)\n",
    "final_dev_preds = np.argmax(weighted_dev_preds, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_mapping = {\n",
    "    'Not_offensive': 0, \n",
    "    'not-Kannada': 1, \n",
    "    'Offensive_Targeted_Insult_Other': 2, \n",
    "    'Offensive_Targeted_Insult_Group': 3, \n",
    "    'Offensive_Untargetede': 4, \n",
    "    'Offensive_Targeted_Insult_Individual': 5\n",
    "}\n",
    "\n",
    "# Collecting Text and Labels\n",
    "train_batch_sentences = list(kannada_train['text'])\n",
    "train_batch_labels =  [label_mapping[x] for x in kannada_train['label']]\n",
    "dev_batch_sentences = list(kannada_dev['text'])\n",
    "dev_batch_labels =  [label_mapping[x] for x in kannada_dev['label']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/punyajoy/.conda/envs/nlp/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "y_true = dev_batch_labels\n",
    "y_pred = final_dev_preds\n",
    "target_names = label_mapping.keys()\n",
    "report = classification_report(y_true, y_pred, target_names=target_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                      precision    recall  f1-score   support\n",
      "\n",
      "                       Not_offensive       0.78      0.85      0.81       426\n",
      "                         not-Kannada       0.74      0.84      0.79       191\n",
      "     Offensive_Targeted_Insult_Other       0.00      0.00      0.00        16\n",
      "     Offensive_Targeted_Insult_Group       0.42      0.31      0.36        45\n",
      "               Offensive_Untargetede       0.43      0.09      0.15        33\n",
      "Offensive_Targeted_Insult_Individual       0.65      0.55      0.60        66\n",
      "\n",
      "                            accuracy                           0.74       777\n",
      "                           macro avg       0.50      0.44      0.45       777\n",
      "                        weighted avg       0.71      0.74      0.72       777\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optimising with GA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " The best solution found:                                                                           \n",
      " [2.45755889 1.81199597 0.46211092 1.63414761 2.65716323 1.27402854\n",
      " 4.01661441 3.30297596 2.12425989 0.70285799 0.745588   3.20394856]\n",
      "\n",
      " Objective function:\n",
      " 0.46137094358593855\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from geneticalgorithm import geneticalgorithm as ga\n",
    "\n",
    "def f(X):\n",
    "    softmax_w = np.exp(X)/np.sum(np.exp(X))\n",
    "    weighted_all_dev_preds = np.array([sw*dpreds for sw, dpreds in zip(softmax_w, all_dev_preds)])\n",
    "    weighted_dev_preds = np.sum(weighted_all_dev_preds, axis = 0)\n",
    "    final_dev_preds = np.argmax(weighted_dev_preds, axis = 1)\n",
    "\n",
    "    y_true = dev_batch_labels\n",
    "    y_pred = final_dev_preds\n",
    "    score = f1_score(y_true, y_pred, average='macro')\n",
    "    return 1-score\n",
    "\n",
    "varbound=np.array([[0, 5]]*all_dev_preds.shape[0])\n",
    "\n",
    "model=ga(function=f,dimension=all_dev_preds.shape[0],variable_type='real',variable_boundaries=varbound)\n",
    "\n",
    "model.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "convergence=model.report\n",
    "solution=model.output_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'variable': array([2.45755889, 1.81199597, 0.46211092, 1.63414761, 2.65716323,\n",
       "        1.27402854, 4.01661441, 3.30297596, 2.12425989, 0.70285799,\n",
       "        0.745588  , 3.20394856]),\n",
       " 'function': 0.46137094358593855}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = solution['variable']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "saved_model_filename = 'GA_v1_kannada'\n",
    "\n",
    "with open(\"../../dev_preds/weights_\" + saved_model_filename + \".pickle\", 'rb') as handle:\n",
    "    mw = pickle.load(handle)\n",
    "    \n",
    "X = [mw[index][0] for index in mw.keys()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2.4575588857477992,\n",
       " 1.8119959704070476,\n",
       " 0.462110920903549,\n",
       " 1.6341476131375288,\n",
       " 2.65716323320213,\n",
       " 1.2740285448075563,\n",
       " 4.016614405001666,\n",
       " 3.302975964858024,\n",
       " 2.124259887478466,\n",
       " 0.7028579920165603,\n",
       " 0.7455879960046707,\n",
       " 3.2039485588581016]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "softmax_w = np.exp(X)/np.sum(np.exp(X))\n",
    "weighted_all_dev_preds = np.array([sw*dpreds for sw, dpreds in zip(softmax_w, all_dev_preds)])\n",
    "weighted_dev_preds = np.sum(weighted_all_dev_preds, axis = 0)\n",
    "final_dev_preds = np.argmax(weighted_dev_preds, axis = 1)\n",
    "\n",
    "y_true = dev_batch_labels\n",
    "y_pred = final_dev_preds\n",
    "target_names = label_mapping.keys()\n",
    "report = classification_report(y_true, y_pred, target_names=target_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                      precision    recall  f1-score   support\n",
      "\n",
      "                       Not_offensive       0.78      0.85      0.82       426\n",
      "                         not-Kannada       0.76      0.82      0.79       191\n",
      "     Offensive_Targeted_Insult_Other       0.75      0.19      0.30        16\n",
      "     Offensive_Targeted_Insult_Group       0.50      0.36      0.42        45\n",
      "               Offensive_Untargetede       0.46      0.18      0.26        33\n",
      "Offensive_Targeted_Insult_Individual       0.68      0.62      0.65        66\n",
      "\n",
      "                            accuracy                           0.75       777\n",
      "                           macro avg       0.66      0.50      0.54       777\n",
      "                        weighted avg       0.74      0.75      0.74       777\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5386290564140614"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(y_true, y_pred, average='macro')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "saved_model_filename = 'GA_v1_kannada'\n",
    "np.savetxt(\"../../dev_preds/\" + saved_model_filename + \".csv\", final_dev_preds, delimiter=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(\"../../model_prediction_probs/\"+saved_model_filename+\".npy\", weighted_dev_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'load_model_filenames' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-df80b6c3c0d2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0ma\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mz\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mz\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mload_model_filenames\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msolution\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'variable'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_pretrained_keys\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'load_model_filenames' is not defined"
     ]
    }
   ],
   "source": [
    "a = {x:(y,z) for x, y, z in zip(load_model_filenames, np.array(solution['variable']), model_pretrained_keys)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'saved_model_filename' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-84bdf4aed05d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpickle\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"../../dev_preds/weights_\"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0msaved_model_filename\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\".pickle\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'wb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprotocol\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mHIGHEST_PROTOCOL\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'saved_model_filename' is not defined"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "with open(\"../../dev_preds/weights_\" + saved_model_filename + \".pickle\", 'wb') as handle:\n",
    "    pickle.dump(a, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:.conda-nlp]",
   "language": "python",
   "name": "conda-env-.conda-nlp-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
